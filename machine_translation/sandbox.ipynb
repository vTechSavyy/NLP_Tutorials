{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(100, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.3503,  0.3081, -1.2628, -0.9445, -0.5948],\n",
      "         [ 0.0323, -0.2842,  1.0266,  0.8103, -0.6095],\n",
      "         [-0.7855,  0.2334,  0.5135,  0.2064,  0.4160]],\n",
      "\n",
      "        [[ 0.1088, -0.5876, -0.9239, -1.1575, -0.5690],\n",
      "         [-0.1505, -0.7596, -0.1152, -0.8817, -0.6129],\n",
      "         [ 2.1962,  1.0490, -0.1183, -0.4803,  0.7735]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "word_indices = torch.tensor([[0, 12, 35], [14, 25, 32]])\n",
    "embeds = embedding(word_indices)\n",
    "print(embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 8, 10])\n"
     ]
    }
   ],
   "source": [
    "from SingleHeadAttention import SingleHeadAttention\n",
    "import torch\n",
    "\n",
    "# Create a simple single head attention layer:\n",
    "embed_dim = 10\n",
    "query_dim = 5\n",
    "\n",
    "single_headed_attn = SingleHeadAttention(embed_dim, query_dim)\n",
    "\n",
    "# Create random source and target sequences:\n",
    "batch_size = 32\n",
    "src_seq_length    = 16\n",
    "target_seq_length = 8\n",
    "\n",
    "src_seq    = torch.randn(batch_size, src_seq_length, embed_dim)\n",
    "target_seq = torch.randn(batch_size, target_seq_length, embed_dim)\n",
    "\n",
    "# Try out the forward operation of the layer:\n",
    "attn_output = single_headed_attn(src_seq, target_seq)\n",
    "\n",
    "print(attn_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (512x512 and 32x512)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/savio/Documents/Tutorials/NLP_Tutorials/machine_translation/sandbox.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/savio/Documents/Tutorials/NLP_Tutorials/machine_translation/sandbox.ipynb#W4sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m src_seq    \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(batch_size, src_seq_length, embed_dim)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/savio/Documents/Tutorials/NLP_Tutorials/machine_translation/sandbox.ipynb#W4sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m target_seq \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(batch_size, target_seq_length, embed_dim)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/savio/Documents/Tutorials/NLP_Tutorials/machine_translation/sandbox.ipynb#W4sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m outputs, output_weights \u001b[39m=\u001b[39m multi_headed_attn(target_seq, src_seq, src_seq) \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/savio/Documents/Tutorials/NLP_Tutorials/machine_translation/sandbox.ipynb#W4sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mprint\u001b[39m(outputs\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/savio/Documents/Tutorials/NLP_Tutorials/machine_translation/sandbox.ipynb#W4sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mprint\u001b[39m(output_weights\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/activation.py:1191\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         query, key, value \u001b[39m=\u001b[39m [x\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m (query, key, value)]\n\u001b[1;32m   1190\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_qkv_same_embed_dim:\n\u001b[0;32m-> 1191\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1192\u001b[0m         query, key, value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_dim, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads,\n\u001b[1;32m   1193\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_weight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_bias,\n\u001b[1;32m   1194\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias_k, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias_v, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_zero_attn,\n\u001b[1;32m   1195\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout_proj\u001b[39m.\u001b[39mweight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout_proj\u001b[39m.\u001b[39mbias,\n\u001b[1;32m   1196\u001b[0m         training\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining,\n\u001b[1;32m   1197\u001b[0m         key_padding_mask\u001b[39m=\u001b[39mkey_padding_mask, need_weights\u001b[39m=\u001b[39mneed_weights,\n\u001b[1;32m   1198\u001b[0m         attn_mask\u001b[39m=\u001b[39mattn_mask,\n\u001b[1;32m   1199\u001b[0m         use_separate_proj_weight\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   1200\u001b[0m         q_proj_weight\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mq_proj_weight, k_proj_weight\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk_proj_weight,\n\u001b[1;32m   1201\u001b[0m         v_proj_weight\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mv_proj_weight,\n\u001b[1;32m   1202\u001b[0m         average_attn_weights\u001b[39m=\u001b[39maverage_attn_weights,\n\u001b[1;32m   1203\u001b[0m         is_causal\u001b[39m=\u001b[39mis_causal)\n\u001b[1;32m   1204\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1205\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1206\u001b[0m         query, key, value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_dim, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads,\n\u001b[1;32m   1207\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_weight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_bias,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1214\u001b[0m         average_attn_weights\u001b[39m=\u001b[39maverage_attn_weights,\n\u001b[1;32m   1215\u001b[0m         is_causal\u001b[39m=\u001b[39mis_causal)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py:5233\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5231\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   5232\u001b[0m         b_q, b_k, b_v \u001b[39m=\u001b[39m in_proj_bias\u001b[39m.\u001b[39mchunk(\u001b[39m3\u001b[39m)\n\u001b[0;32m-> 5233\u001b[0m     q, k, v \u001b[39m=\u001b[39m _in_projection(query, key, value, q_proj_weight, k_proj_weight, v_proj_weight, b_q, b_k, b_v)\n\u001b[1;32m   5235\u001b[0m \u001b[39m# prep attention mask\u001b[39;00m\n\u001b[1;32m   5237\u001b[0m attn_mask \u001b[39m=\u001b[39m _canonical_mask(\n\u001b[1;32m   5238\u001b[0m     mask\u001b[39m=\u001b[39mattn_mask,\n\u001b[1;32m   5239\u001b[0m     mask_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mattn_mask\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5243\u001b[0m     check_other\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   5244\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py:4840\u001b[0m, in \u001b[0;36m_in_projection\u001b[0;34m(q, k, v, w_q, w_k, w_v, b_q, b_k, b_v)\u001b[0m\n\u001b[1;32m   4837\u001b[0m \u001b[39massert\u001b[39;00m b_q \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m b_q\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m (Eq,), \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mexpecting query bias shape of \u001b[39m\u001b[39m{\u001b[39;00m(Eq,)\u001b[39m}\u001b[39;00m\u001b[39m, but got \u001b[39m\u001b[39m{\u001b[39;00mb_q\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4838\u001b[0m \u001b[39m# assert b_k is None or b_k.shape == (Eq,), f\"expecting key bias shape of {(Eq,)}, but got {b_k.shape}\"\u001b[39;00m\n\u001b[1;32m   4839\u001b[0m \u001b[39m# assert b_v is None or b_v.shape == (Eq,), f\"expecting value bias shape of {(Eq,)}, but got {b_v.shape}\"\u001b[39;00m\n\u001b[0;32m-> 4840\u001b[0m \u001b[39mreturn\u001b[39;00m linear(q, w_q, b_q), linear(k, w_k, b_k), linear(v, w_v, b_v)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (512x512 and 32x512)"
     ]
    }
   ],
   "source": [
    "from torch.nn import MultiheadAttention\n",
    "import torch\n",
    "\n",
    "# Create a simple multi-head attention layer:\n",
    "embed_dim = 512\n",
    "key_dim   = 32\n",
    "value_dim = 64\n",
    "num_heads = 8\n",
    "\n",
    "multi_headed_attn = MultiheadAttention(embed_dim, num_heads, 0.25, False, False,batch_first=True)\n",
    "\n",
    "# Create inputs for the multi-head attn layer:\n",
    "# Create random source and target sequences:\n",
    "batch_size = 32\n",
    "src_seq_length    = 16\n",
    "target_seq_length = 8\n",
    "\n",
    "src_seq    = torch.randn(batch_size, src_seq_length, embed_dim)\n",
    "target_seq = torch.randn(batch_size, target_seq_length, embed_dim)\n",
    "\n",
    "outputs, output_weights = multi_headed_attn(target_seq, src_seq, src_seq) \n",
    "\n",
    "print(outputs.shape)\n",
    "print(output_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Test the mask generation logic:\n",
    "DEVICE = 'cpu'\n",
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "\n",
    "tgt_mask = generate_square_subsequent_mask(8)\n",
    "\n",
    "print(tgt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "randint() received an invalid combination of arguments - got (tuple, int, int), but expected one of:\n * (int high, tuple of ints size, *, torch.Generator generator, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (int high, tuple of ints size, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (int low, int high, tuple of ints size, *, torch.Generator generator, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (int low, int high, tuple of ints size, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/savio/Documents/Tutorials/NLP_Tutorials/machine_translation/sandbox.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/savio/Documents/Tutorials/NLP_Tutorials/machine_translation/sandbox.ipynb#W6sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     tgt_padding_mask \u001b[39m=\u001b[39m (tgt \u001b[39m==\u001b[39m PAD_IDX)\u001b[39m.\u001b[39mtranspose(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/savio/Documents/Tutorials/NLP_Tutorials/machine_translation/sandbox.ipynb#W6sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m src_mask, tgt_mask, src_padding_mask, tgt_padding_mask\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/savio/Documents/Tutorials/NLP_Tutorials/machine_translation/sandbox.ipynb#W6sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m src \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandint((\u001b[39m8\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m), \u001b[39m0\u001b[39m, \u001b[39m20\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/savio/Documents/Tutorials/NLP_Tutorials/machine_translation/sandbox.ipynb#W6sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m tgt \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandint((\u001b[39m10\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m), \u001b[39m0\u001b[39m, \u001b[39m20\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/savio/Documents/Tutorials/NLP_Tutorials/machine_translation/sandbox.ipynb#W6sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m src_mask, tgt_mask, src_padding_mask, tgt_padding_mask \u001b[39m=\u001b[39m create_mask(src, tgt)\n",
      "\u001b[0;31mTypeError\u001b[0m: randint() received an invalid combination of arguments - got (tuple, int, int), but expected one of:\n * (int high, tuple of ints size, *, torch.Generator generator, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (int high, tuple of ints size, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (int low, int high, tuple of ints size, *, torch.Generator generator, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (int low, int high, tuple of ints size, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n"
     ]
    }
   ],
   "source": [
    "PAD_IDX = 10\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
    "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask\n",
    "\n",
    "src = torch.randint((8, 2, 1), 0, 20)\n",
    "tgt = torch.randint((10, 2, 1), 0, 20)\n",
    "src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt)\n",
    "\n",
    "print(src_padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "05f98a8d37b882c91b019f6702e08d1b1eccf9d9c5d55920243c1d4693a1e7b1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
